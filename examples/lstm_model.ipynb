{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Welcome to ProgPy's LSTM Model Tutorial"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we generate fake data using the ThrownObject model. This is a case where we're generating a surrogate model from the physics-based model. For cases where you're generating a model from data (e.g., collected from a testbed or a real-world environment), you'll replace that generated data with your own. We then use the generated model and compare to the original model.\n",
    "\n",
    "Finally, we repeat the exercise with data from the more complex BatteryElectroChemEOD model."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we talk about what a LSTM is, we must first describe the data_model class!\n",
    "\n",
    "The data_model class is an abstract base class for all Data Models (e.g., `LSTMStateTransitionModel`). The class defines the interface and all common tools! To create a new Data-Driven model, first subclass data_model, then define the abstract methods from this class and `prog_models.PrognosticsModel`. (To read more, consider viewing https://nasa.github.io/progpy/api_ref/prog_models/DataModel.html#prog_models.data_models.DataModel)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Within the data_model class, there are two functions that are worthwhile to look at.\n",
    "\n",
    "#### from_data\n",
    "\n",
    "The first is an abstract class method `from_data`. We can use `from_data` to create a Data Model from data. This class is overwritten by specific data-driven classes (e.g., `LSTMStateTransitionModel`). Furthermore, the method takes in a myriad of keyword arguments.\n",
    "\n",
    "Keyword Arguments:\n",
    "* __`times`__ __(list[list])__: list of input data for use in data. Each element is the times for a single run of size (n_times)\n",
    "* __`inputs`__ __(list[np.array])__: list of :term:`input` data for use in data. Each element is the inputs for a single run of size (n_times, n_inputs)\n",
    "* __`states`__ __(list[np.array])__: list of :term:`state` data for use in data. Each element is the states for a single run of size (n_times, n_states)\n",
    "* __`outputs`__ __(list[np.array])__: list of :term:`output` data for use in data. Each element is the outputs for a single run of size (n_times, n_outputs)\n",
    "* __`event_states`__ __(list[np.array])__: list of :term:`event state` data for use in data. Each element is the event states for a single run of size (n_times, n_event_states)\n",
    "* __`time_of_event`__ __(np.array)__: Array of time of event data for use in data. Each element is the time of event for a single run of size (n_samples, n_events)\n",
    "* __`input_keys`__ __(list[str])__: List of :term:`input` keys\n",
    "* __`state_keys`__ __(list[str])__: List of :term:`state` keys\n",
    "* __`output_keys`__ __(list[str])__: List of :term:`output` keys\n",
    "* __`event_keys`__ __(list[str])__: List of :term:`event` keys"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### from_model\n",
    "\n",
    "The second method is a class method `from_model`. We can use `from_model` to create a Data Model from an existing PrognosticsModel (i.e., a `surrogate` model). Generates data through simulation with supplied load functions. Then calls `from_data` to generate the model. The method has a few arguments a some keyword arguments as well.\n",
    "\n",
    "Arguments:\n",
    "* __`m`__ __(PrognosticsModel)__: Model to generate data from\n",
    "* __`load_functions`__ __(list[function])__: Each index is a callable loading function of (t, x = None) -> z used to predict :term:`future load` at a given time (t) and :term:`state` (x)\n",
    "\n",
    "Keyword Arguments:\n",
    "* __`add_dt`__ __(bool)__: If the timestep should be added as an input\n",
    "\n",
    "Returns:\n",
    "* __`DataModel`__: Trained PrognosticsModel\n",
    "\n",
    "Furthermore, `from_model` has additional configurations parameters from `prog_models.PrognosticsModel.simulate_to_threshold`. These can be an array (of same length as load_functions) of config for each individual sim, or one value to apply to all. Additional configuration parameters can also be found from `from_data`\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "______________________________________________________________________________________________________________________________________________________________________________________________________________\n",
    "\n",
    "With our baseline understanding of `data_model`, we can now create the subclass `lstm_model`! \n",
    "\n",
    "The `lstm_model` is a State Transition Model with no `event` using an Keras LSTM Model. State transition models map from the `input` at time t and `output` at time t-1 plus historical data from a set window to the `output` at time t.\n",
    "\n",
    "Most users will use the `LSTMStateTransitionModel.from_data` method to create a model, but the model can be created by passing in a model directly into the constructor. The LSTM model in this method maps from [u_t-n+1, z_t-n, ..., u_t, z_t-1] to z_t. Past `input` are stored in the `model` internal `state`. Actual calculation of `output` is performed when `LSTMStateTransitionModel.output` is called. When using in simulation that may not be until the simulation results are accessed.\n",
    "\n",
    "Arguments:\n",
    "* __`output_model`__ __(keras.Model)__: If a state model is present, maps from the state_model outputs to model :term:`output`. Otherwise, maps from model inputs to model :term:`output`\n",
    "* __`state_model`__ __(keras.Model, optional)__: Keras model to use for state transition\n",
    "* __`event_state_model`__ __(keras.Model, optional)__: If a state model is present, maps from the state_model outputs to :term:`event state`. Otherwise, maps from model inputs to :term:`event state`\n",
    "* __`t_met_model`__ __(keras.Model, optional)__: If a state model is present, maps from the state_model outputs to if the threshold has been met. Otherwise, maps from model inputs to if the threshold has not been met\n",
    "\n",
    "Keyword Arguments:\n",
    "* __`input_keys`__ __(list[str])__: List of input keys\n",
    "* __`output_keys`__ __(list[str])__: List of output keys\n",
    "* __`event_keys`__ __(list[str])__: List of event keys\n",
    "\n",
    "Attributes:\n",
    "* __`model`__ __(keras.Model)__: Keras model to use for state transition\n",
    "\n",
    "For more information on LSTM Models, please refer to our documentation at https://nasa.github.io/progpy/api_ref/prog_models/DataModel.html#prog_models.data_models.LSTMStateTransitionModel!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With our newfound knowledge, let's start with a basic example of using the lstm model!\n",
    "\n",
    "We first must import the necessary modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from prog_models.data_models import LSTMStateTransitionModel\n",
    "from prog_models.models import ThrownObject, BatteryElectroChemEOD"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1) Set Timestep\n",
    "\n",
    "For our first example, we will create a model for a specific timestep. The model will only work with that timestep. This is useful if you know the timestep you would like to use!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TIMESTEP = 0.1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 1) Generate Data\n",
    "\n",
    "For our first step, we'll use the ThrownObject model to generate data. For cases where you're generating a model from data (e.g., collected from a testbed or a real-world environment), you'll replace that generated data with your own."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Generating data')\n",
    "m = ThrownObject()\n",
    "\n",
    "def future_loading(t, x=None):\n",
    "    return m.InputContainer({})  # No input for thrown object \n",
    "\n",
    "data = m.simulate_to_threshold(future_loading, threshold_keys='impact', save_freq=TIMESTEP, dt=TIMESTEP)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 2) Generate Model\n",
    "\n",
    "Next, we'll use the LSTMStateTransitionModel class to generate a model from the generated data!\n",
    "\n",
    "Some information to note is that we are passing in the simulated data from the ThrownObject to our LSTM Model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Building model...')\n",
    "m2 = LSTMStateTransitionModel.from_data(\n",
    "    inputs=[data.inputs],\n",
    "    outputs=[data.outputs],\n",
    "    window=4,\n",
    "    epochs=30,  # Maximum number of epochs, may stop earlier if early stopping enabled\n",
    "    output_keys=['x'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we are using the `LSTMStateTransitionModel.from_data`. Remember that in `data_model`, `from_data()` was an abstract method. In other words, in our LSTM model, we must have redefined the `from_data` method! Let's take a look at how the method looks now:\n",
    "\n",
    "Arguments:\n",
    "* __`inputs`__ __(list[np.array])__: list of `input` data for use in data. Each element is the inputs for a single run of size (n_times, n_inputs)\n",
    "* __`outputs`__ __(list[np.array])__: list of `output` data for use in data. Each element is the outputs for a single run of size (n_times, n_outputs)\n",
    "* __`event_states`__ __(list[np.array], optional)__: list of `event state` data for use in data. Each element is the event state for a single run of size (n_times, n_events)\n",
    "* __`t_met`__ __(list[np.array], optional)__: list of `threshold` met data for use in data. Each element is if the threshold has been met for a single run of size (n_times, n_events) \n",
    "\n",
    "Keyword Arguments:\n",
    "* __`window`__ __(int)__: Number of historical points used in the model. I.e, if window is 3, the model will map from [t-3, t-2, t-1] to t\n",
    "* __`input_keys`__ __(list[str])__: List of keys to use to identify :term:`input`. If not supplied u[#] will be used to identify inputs\n",
    "* __`output_keys`__ __(list[str])__: List of keys to use to identify :term:`output`. If not supplied z[#] will be used to identify outputs\n",
    "* __`event_keys`__ __(list[str])__: List of keys to use to identify events for :term:`event state` and :term:`threshold` met. If not supplied event[#] will be used to identify events\n",
    "* __`validation_percentage`__ __(float)__: Percentage of data to use for validation, between 0-1\n",
    "* __`epochs`__ __(int)__: Number of epochs (i.e., iterations) to train the model. More epochs means better results (to a point), but more time to train. Note: large numbers of epochs may result in overfitting\n",
    "* __`layers`__ __(int)__: Number of LSTM layers to use. More layers can represent more complex systems, but are less efficient. Note: 2 layers is typically enough for most complex systems. Default: 1\n",
    "* __`units`__ __(int or list[int])__: number of units (i.e., dimensionality of output state) used in each LSTM layer. Using a scalar value will use the same number of units for each layer\n",
    "* __`activation`__ __(str or list[str])__: Activation function to use for each layer\n",
    "* __`dropout`__ __(float)__: Dropout rate to be applied. Dropout helps avoid overfitting\n",
    "* __`normalize`__ __(bool)__: If the data should be normalized. This is recommended for most cases\n",
    "* __`early_stopping`__ __(bool)__: If early stopping is desired. Default is True\n",
    "* __`early_stop.cfg`__ __(dict)__: Configuration to pass into early stopping callback (if enabled). See keras documentation (https://keras.io/api/callbacks/early_stopping) for options. E.g., {'patience': 5}\n",
    "* __`workers`__ __(int)__: Number of workers to use when training. One worker indicates no multiprocessing\n",
    "\n",
    "Returns:\n",
    "* __`LSTMStateTransitionModel`__: Generated Model\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the model that we created, we can see the training history! Intuitively, the history should show that the model is progressively getting better (i.e., loss goes down). If `val_loss` starts going up again, then we may be overtraining!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m2.plot_history()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 3: Use model to simulate_to time of threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Simulating with generated model...')\n",
    "\n",
    "t_counter = 0\n",
    "x_counter = m.initialize()\n",
    "\n",
    "def future_loading2(t, x=None):\n",
    "    global t_counter, x_counter\n",
    "    z = m.output(x_counter)\n",
    "    z = m2.InputContainer(z.matrix)\n",
    "    x_counter = m.next_state(x_counter, future_loading(t), t - t_counter)\n",
    "    t_counter = t\n",
    "    return z\n",
    "\n",
    "results2 = m2.simulate_to(data.times[-1], future_loading2, dt=TIMESTEP, save_freq=TIMESTEP)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is worth noting that our future loading function is a bit complicated here. Loading for the resulting model includes the data inputs, and the output from the last timestep."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 4: Compare model to original model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Comparing results...')\n",
    "data.outputs.plot(title='original model')\n",
    "results2.outputs.plot(title='generated model')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 2) Variable Timestep\n",
    "\n",
    "Now, we will create a model to work with any timestep! We do this by adding timestep as a variable in the model."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 1: Generate additional data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use data generated above, but we also want data at additional timesteps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n------------------------------------------\\nExample 2...')\n",
    "print('Generating additional data...')\n",
    "data_half = m.simulate_to_threshold(future_loading, threshold_keys='impact', save_freq=TIMESTEP/2, dt=TIMESTEP/2)\n",
    "data_quarter = m.simulate_to_threshold(future_loading, threshold_keys='impact', save_freq=TIMESTEP/4, dt=TIMESTEP/4)\n",
    "data_twice = m.simulate_to_threshold(future_loading, threshold_keys='impact', save_freq=TIMESTEP*2, dt=TIMESTEP*2)\n",
    "data_four = m.simulate_to_threshold(future_loading, threshold_keys='impact', save_freq=TIMESTEP*4, dt=TIMESTEP*4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 2: Data Prep\n",
    "\n",
    "We need to add the timestep as a input!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u = np.array([[TIMESTEP] for _ in data.inputs])\n",
    "u_half = np.array([[TIMESTEP/2] for _ in data_half.inputs])\n",
    "u_quarter = np.array([[TIMESTEP/4] for _ in data_quarter.inputs])\n",
    "u_twice = np.array([[TIMESTEP*2] for _ in data_twice.inputs])\n",
    "u_four = np.array([[TIMESTEP*4] for _ in data_four.inputs])\n",
    "\n",
    "input_data = [u, u_half, u_quarter, u_twice, u_four]\n",
    "output_data = [data.outputs, data_half.outputs, data_quarter.outputs, data_twice.outputs, data_four.outputs]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 3: Generate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Building model...')\n",
    "m3 = LSTMStateTransitionModel.from_data(\n",
    "    inputs=input_data,\n",
    "    outputs=output_data,\n",
    "    window=4,\n",
    "    epochs=30,\n",
    "    input_keys=['dt'],\n",
    "    output_keys=['x'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__NOTE__: Since we're generating from a model, we could also have done this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXAMPLE_MODEL = LSTMStateTransitionModel.from_model(\n",
    "    m,\n",
    "    [future_loading for _ in range(5)],\n",
    "    dt = [TIMESTEP, TIMESTEP/2, TIMESTEP/4, TIMESTEP*2, TIMESTEP*4],\n",
    "    window=4,\n",
    "    epochs=30)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that we are passing in `input_data` and `output_data` that is made up of multiple Timesteps.\n",
    "\n",
    "Let's take a look at the training history!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m3.plot_history()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly to the previous example, the more we train, the lower our loss!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 4: Simulate with model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_counter = 0\n",
    "x_counter = m.initialize()\n",
    "\n",
    "def future_loading3(t, x=None):\n",
    "    global t_counter, x_counter\n",
    "    z = m3.InputContainer({'x_t-1': x_counter['x'], 'dt': t - t_counter})\n",
    "    x_counter = m.next_state(x_counter, future_loading(t), t - t_counter)\n",
    "    t_counter = t\n",
    "    return z\n",
    "\n",
    "data = m.simulate_to(data.times[-1], future_loading, dt=TIMESTEP*3, save_freq=TIMESTEP*3)\n",
    "results3 = m3.simulate_to(data.times[-1], future_loading3, dt=TIMESTEP*3, save_freq=TIMESTEP*3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are using the new dt, not used in the training. by using a dt not used in the training, this will demonstrate the mode's ability to handle different timesteps not part of the the training set!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 5: Compare Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Comparing results...')\n",
    "data.outputs.plot(title='original model')\n",
    "results3.outputs.plot(title='generated model')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
